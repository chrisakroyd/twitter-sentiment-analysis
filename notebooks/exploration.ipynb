{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Exploration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from afinn import Afinn\n",
    "from src.load_data import get_data_sem_eval\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = Afinn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3382\n"
     ]
    }
   ],
   "source": [
    "print(len(words._dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_140 = pd.read_csv('../data/training.1600000.processed.noemoticon.csv', names=['class', 'id', 'date', 'query', 'user', 'text'], encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral     22144\n",
      "positive    19521\n",
      "negative     7701\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sem_eval = get_data_sem_eval('../data/full_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2140577792</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Picturehouse's, Pink Floyd's, 'Roger Waters: T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1026121727</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Order Go Set a Watchman in store or through ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-149524480</th>\n",
       "      <td>negative</td>\n",
       "      <td>If these runway renovations at the airport pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521601024</th>\n",
       "      <td>neutral</td>\n",
       "      <td>If you could ask an onstage interview question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010447872</th>\n",
       "      <td>positive</td>\n",
       "      <td>A portion of book sales from our Harper Lee/Go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                class                                               text\n",
       "id                                                                      \n",
       " 2140577792   neutral  Picturehouse's, Pink Floyd's, 'Roger Waters: T...\n",
       "-1026121727   neutral  Order Go Set a Watchman in store or through ou...\n",
       "-149524480   negative  If these runway renovations at the airport pre...\n",
       " 521601024    neutral  If you could ask an onstage interview question...\n",
       " 2010447872  positive  A portion of book sales from our Harper Lee/Go..."
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sem_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ftfy import fix_text\n",
    "import re\n",
    "\n",
    "VALID_TAGS = {'<ALLCAPS>', '<IP>', '<URL>', '<EMAIL>', '<USER>', '<DATE>', '<TIME>', '<NUMBER>', '<CURRENCY>',\n",
    "              '<REPEAT>', '<ELONG>', '<EMPTY>', '<OOV>'}\n",
    "\n",
    "FLAGS = re.MULTILINE | re.DOTALL\n",
    "\n",
    "REGEX_LOOKUP = {\n",
    "    \"DATE\": \"(?:(?:(?:(?:(?<!:)\\\\b\\\\'?\\\\d{1,4},? ?)?\\\\b(?:[Jj]an(?:uary)?|[Ff]eb(?:ruary)?|[Mm]ar(?:ch)?|[Aa]pr(?:il)?|May|[Jj]un(?:e)?|[Jj]ul(?:y)?|[Aa]ug(?:ust)?|[Ss]ept?(?:ember)?|[Oo]ct(?:ober)?|[Nn]ov(?:ember)?|[Dd]ec(?:ember)?)\\\\b(?:(?:,? ?\\\\'?)?\\\\d{1,4}(?:st|nd|rd|n?th)?\\\\b(?:[,\\\\/]? ?\\\\'?\\\\d{2,4}[a-zA-Z]*)?(?: ?- ?\\\\d{2,4}[a-zA-Z]*)?(?!:\\\\d{1,4})\\\\b))|(?:(?:(?<!:)\\\\b\\\\'?\\\\d{1,4},? ?)\\\\b(?:[Jj]an(?:uary)?|[Ff]eb(?:ruary)?|[Mm]ar(?:ch)?|[Aa]pr(?:il)?|May|[Jj]un(?:e)?|[Jj]ul(?:y)?|[Aa]ug(?:ust)?|[Ss]ept?(?:ember)?|[Oo]ct(?:ober)?|[Nn]ov(?:ember)?|[Dd]ec(?:ember)?)\\\\b(?:(?:,? ?\\\\'?)?\\\\d{1,4}(?:st|nd|rd|n?th)?\\\\b(?:[,\\\\/]? ?\\\\'?\\\\d{2,4}[a-zA-Z]*)?(?: ?- ?\\\\d{2,4}[a-zA-Z]*)?(?!:\\\\d{1,4})\\\\b)?))|(?:\\\\b(?<!\\\\d\\\\.)(?:(?:(?:[0123]?[0-9][\\\\.\\\\-\\\\/])?[0123]?[0-9][\\\\.\\\\-\\\\/][12][0-9]{3})|(?:[0123]?[0-9][\\\\.\\\\-\\\\/][0123]?[0-9][\\\\.\\\\-\\\\/][12]?[0-9]{2,3}))(?!\\\\.\\\\d)\\\\b))\",\n",
    "    \"EMAIL\": \"(?:^|(?<=[^\\\\w@.)]))(?:[\\\\w+-](?:\\\\.(?!\\\\.))?)*?[\\\\w+-]@(?:\\\\w-?)*?\\\\w+(?:\\\\.(?:[a-z]{2,})){1,3}(?:$|(?=\\\\b))\",\n",
    "    \"EMOJI\": \"[\\uD83C-\\uDBFF\\uDC00-\\uDFFF]+\",\n",
    "    \"IP\": \"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\n",
    "    \"TIME\": \"(?:(?:\\d+)?\\.?\\d+(?:AM|PM|am|pm|a\\.m\\.|p\\.m\\.))|(?:(?:[0-2]?[0-9]|[2][0-3]):(?:[0-5][0-9])(?::(?:[0-5][0-9]))?(?: ?(?:AM|PM|am|pm|a\\.m\\.|p\\.m\\.))?)\",\n",
    "    \"MONEY\": \"(?:[$€£¢]\\d+(?:[\\.,']\\d+)?(?:[MmKkBb](?:n|(?:il(?:lion)?))?)?)|(?:\\d+(?:[\\.,']\\d+)?[$€£¢])\",\n",
    "    \"URL\": \"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\n",
    "    \"NUMBERS\": \"[-+]?[.\\d]*[\\d]+[:,.\\d]*\"\n",
    "}\n",
    "\n",
    "\n",
    "# Preprocessing Regex's\n",
    "url_regex = re.compile(REGEX_LOOKUP['URL'])\n",
    "ip_regex = re.compile(REGEX_LOOKUP['IP'])\n",
    "date_regex = re.compile(REGEX_LOOKUP['DATE'])\n",
    "emoji_regex = re.compile(REGEX_LOOKUP['EMOJI'])\n",
    "email_regex = re.compile(REGEX_LOOKUP['EMAIL'])\n",
    "time_regex = re.compile(REGEX_LOOKUP['TIME'])\n",
    "money_regex = re.compile(REGEX_LOOKUP['MONEY'])\n",
    "numbers_regex = re.compile(REGEX_LOOKUP['NUMBERS'])\n",
    "control_chars = re.compile('[\\n\\t\\r\\v\\f\\0]')\n",
    "\n",
    "parenthesis_regex = re.compile('([\\[\\]()])')\n",
    "\n",
    "hearts_regex = re.compile(r'<3')\n",
    "users_regex = re.compile(\"@\\w+\")\n",
    "tokenize_punct = re.compile(r'([.,?!\"]{1})')\n",
    "repeated_punct = re.compile('([!?.]){2,}')\n",
    "elongated_words = re.compile(r\"\\b(\\S*?)(.)\\2{2,}\\b\")\n",
    "word_split = re.compile(r'[/\\-_\\\\]')\n",
    "all_caps_regex = re.compile(r'([A-Z]){2,}')\n",
    "hashtag_regex = re.compile(\"#\\S+\")\n",
    "\n",
    "mentions_regex = re.compile('(?<=^|(?<=[^a-zA-Z0-9-_.]))@([A-Za-z_]+[A-Za-z0-9_]+)')\n",
    "\n",
    "def allcaps(text):\n",
    "    text = text.group()\n",
    "    return text.lower() + \" <allcaps> \"\n",
    "\n",
    "\n",
    "def hashtag(text):\n",
    "    text = text.group()\n",
    "    hashtag_body = text[1:]\n",
    "    if hashtag_body.isupper():\n",
    "        result = \"<hashtag> {} <allcaps>\".format(hashtag_body)\n",
    "    else:\n",
    "        test_regex = re.compile(r'((?<=[a-z])[A-Z]|[A-Z](?=[a-z]))')\n",
    "        hashtag_body = test_regex.sub(r' \\1', hashtag_body)\n",
    "        result = \" \".join([\"<hashtag>\"] + hashtag_body.split(r\"(?=[A-Z])\") + [\"</hashtag>\"])\n",
    "    return result\n",
    "\n",
    "class TextPreProcessor:\n",
    "    def __init__(self, embedding_profile=None):\n",
    "        self.embedding_profile = embedding_profile\n",
    "\n",
    "    def preprocess(self, string):\n",
    "        string = self.clean(string)\n",
    "        return string\n",
    "    \n",
    "    def unpack_contractions(self, text):\n",
    "        \"\"\"\n",
    "        Replace *English* contractions in ``text`` str with their unshortened forms.\n",
    "        N.B. The \"'d\" and \"'s\" forms are ambiguous (had/would, is/has/possessive),\n",
    "        so are left as-is.\n",
    "        ---------\n",
    "        Important Note: The function is taken from textacy (https://github.com/chartbeat-labs/textacy).\n",
    "        \"\"\"\n",
    "        text = re.sub(\n",
    "            r\"(\\b)([Aa]re|[Cc]ould|[Dd]id|[Dd]oes|[Dd]o|[Hh]ad|[Hh]as|[Hh]ave|[Ii]s|[Mm]ight|[Mm]ust|[Ss]hould|[Ww]ere|[Ww]ould)n't\",\n",
    "            r\"\\1\\2 not\", text)\n",
    "        text = re.sub(\n",
    "            r\"(\\b)([Hh]e|[Ii]|[Ss]he|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou)'ll\",\n",
    "            r\"\\1\\2 will\", text)\n",
    "        text = re.sub(r\"(\\b)([Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Yy]ou)'re\", r\"\\1\\2 are\",\n",
    "                      text)\n",
    "        text = re.sub(\n",
    "            r\"(\\b)([Ii]|[Ss]hould|[Tt]hey|[Ww]e|[Ww]hat|[Ww]ho|[Ww]ould|[Yy]ou)'ve\",\n",
    "            r\"\\1\\2 have\", text)\n",
    "        # non-standard\n",
    "        text = re.sub(r\"(\\b)([Cc]a)n't\", r\"\\1\\2n not\", text)\n",
    "        text = re.sub(r\"(\\b)([Ii])'m\", r\"\\1\\2 am\", text)\n",
    "        text = re.sub(r\"(\\b)([Ll]et)'s\", r\"\\1\\2 us\", text)\n",
    "        text = re.sub(r\"(\\b)([Ww])on't\", r\"\\1\\2ill not\", text)\n",
    "        text = re.sub(r\"(\\b)([Ss])han't\", r\"\\1\\2hall not\", text)\n",
    "        text = re.sub(r\"(\\b)([Yy])(?:'all|a'll)\", r\"\\1\\2ou all\", text)\n",
    "        return text\n",
    "    \n",
    "    def unpack_placements(self, text):\n",
    "        text = re.sub(r'1[sS][tT]', 'first', text)\n",
    "        text = re.sub(r'2[nN][dD]', 'second', text)\n",
    "        text = re.sub(r'3[rR][dD]', 'third', text)\n",
    "        text = re.sub(r'4[tT][hH]', 'fourth', text)\n",
    "        text = re.sub(r'5[tT][hH]', 'fifth', text)\n",
    "        text = re.sub(r'6[tT][hH]', 'sixth', text)\n",
    "        text = re.sub(r'7[tT][hH]', 'seventh', text)\n",
    "        text = re.sub(r'8[tT][hH]', 'eigth', text)\n",
    "        text = re.sub(r'9[tT][hH]', 'ninth', text)\n",
    "        text = re.sub(r'10[tT][hH]', 'tenth', text)\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def replace_smileys(self, text):\n",
    "        def re_sub(pattern, repl):\n",
    "            return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "        \n",
    "        eyes = r\"[8:=;]\"\n",
    "        nose = r\"['`\\-]?\"\n",
    "        \n",
    "        text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "        text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "        text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "        text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "        \n",
    "        return text\n",
    "\n",
    "    def clean(self, text):\n",
    "        # Fix unicode characters         \n",
    "        text = fix_text(text)\n",
    "        text = unidecode(text)\n",
    "        \n",
    "        # Replace newline characters\n",
    "        text = control_chars.sub(' ', text)\n",
    "        # Replace ips\n",
    "        text = ip_regex.sub(' <ip> ', text)\n",
    "        # Replace URLs\n",
    "        text = url_regex.sub(' <url> ', text)\n",
    "        # Replace Emails\n",
    "        text = email_regex.sub(' <email> ', text)\n",
    "        # Replace User Names\n",
    "        text = users_regex.sub(' <user> ', text)\n",
    "        # Replace Dates/Time\n",
    "        text = date_regex.sub(' <date> ', text)\n",
    "        text = time_regex.sub(' <time> ', text)\n",
    "        # Replace money symbols\n",
    "        text = money_regex.sub(' <currency> ', text)\n",
    "        \n",
    "        text = self.unpack_placements(text)\n",
    "        text = self.replace_smileys(text)\n",
    "        text = word_split.sub(' ', text)\n",
    "        \n",
    "        text = hashtag_regex.sub(hashtag, text)\n",
    "        \n",
    "        text = hearts_regex.sub(' <heart> ', text)\n",
    "        # Replace Numbers\n",
    "        text = numbers_regex.sub(' <number> ', text)\n",
    "        \n",
    "        text = parenthesis_regex.sub(r' \\1 ', text)\n",
    "        \n",
    "        # Remove multi spaces\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        \n",
    "        text = repeated_punct.sub(r' \\1 <repeat> ', text)\n",
    "\n",
    "        text = tokenize_punct.sub(r' \\1 ', text)\n",
    "        \n",
    "        text = all_caps_regex.sub(allcaps, text)\n",
    "        # text = elongated_words.sub(r\"\\1\", text)\n",
    "        text = elongated_words.sub(r\"\\1\\2 <elong> \", text)\n",
    "        \n",
    "        text = text.replace('&', ' and ')\n",
    "        text = text.replace('@', ' at ')\n",
    "        \n",
    "        # Remove a load of unicode emoji characters\n",
    "        text = emoji_regex.sub('', text)\n",
    "        text = self.unpack_contractions(text)\n",
    "\n",
    "        # Remove multi spaces\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        # Remove ending space if any\n",
    "        if len(text) > 1:\n",
    "            text = re.sub('\\s+$', '', text)\n",
    "\n",
    "        # If this string is a single space replace with an <empty> tag.\n",
    "        if text == ' ':\n",
    "            text = '<EMPTY>'\n",
    "\n",
    "        return text.strip().lower()\n",
    "    \n",
    "def tokenize(text):\n",
    "        # Different regex parts for smiley faces\n",
    "        eyes = r\"[8:=;]\"\n",
    "        nose = r\"['`\\-]?\"\n",
    "\n",
    "        # function so code less repetitive\n",
    "        def re_sub(pattern, repl):\n",
    "            return re.sub(pattern, repl, text, flags=FLAGS)\n",
    "\n",
    "        text = re_sub(r\"https?:\\/\\/\\S+\\b|www\\.(\\w+\\.)+\\S*\", \"<url>\")\n",
    "        text = re_sub(r\"{}{}[)dD]+|[)dD]+{}{}\".format(eyes, nose, nose, eyes), \"<smile>\")\n",
    "        text = re_sub(r\"{}{}p+\".format(eyes, nose), \"<lolface>\")\n",
    "        text = re_sub(r\"{}{}\\(+|\\)+{}{}\".format(eyes, nose, nose, eyes), \"<sadface>\")\n",
    "        text = re_sub(r\"{}{}[\\/|l*]\".format(eyes, nose), \"<neutralface>\")\n",
    "        text = re_sub(r\"/\", \" / \")\n",
    "        text = re_sub(r\"@\\w+\", \"<user>\")\n",
    "        text = re_sub(r\"<3\", \"<heart>\")\n",
    "        text = re_sub(r\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<number>\")\n",
    "        text = re_sub(r\"#\\S+\", hashtag)\n",
    "        text = re_sub(r\"([!?.]){2,}\", r\"\\1 <repeat>\")\n",
    "        text = re_sub(r\"\\b(\\S*?)(.)\\2{2,}\\b\", r\"\\1\\2 <elong>\")\n",
    "\n",
    "        text = mentions_regex.sub('<mention>', text)\n",
    "        text = re_sub(r\"([A-Z]){2,}\", allcaps)\n",
    "\n",
    "        return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The Mariah Carey &amp; Justin Bieber Collaboration Why You Mad Is HERE! Listen!: How exciting! On Saturday, the Mariah Carey and Justin B...\n",
      "\n",
      "Processed Old: the mariah carey &amp; justin bieber collaboration why you mad is here <allcaps> ! listen!: how exciting! on saturday, the mariah carey and justin b. <repeat>\n",
      "\n",
      "Processed New: the mariah carey and justin bieber collaboration why you mad is here <allcaps> ! listen ! : how exciting ! on saturday , the mariah carey and justin b . <repeat>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_sample = sem_eval.sample(n=1).iloc[0]['text']\n",
    "\n",
    "print('Original: ' + text_sample +'\\n')\n",
    "print('Processed Old: ' + tokenize(text_sample) +'\\n')\n",
    "print('Processed New: ' + preprocessor.preprocess(text_sample) +'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
